# Tencent is pleased to support the open source community by making BK-BASE 蓝鲸基础平台 available.
#
# Copyright (C) 2021 THL A29 Limited, a Tencent company.  All rights reserved.
#
# BK-BASE 蓝鲸基础平台 is licensed under the MIT License.
#
# License for BK-BASE 蓝鲸基础平台:
# --------------------------------------------------------------------
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial
# portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
# NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.
spark.master yarn
spark.deploy-mode client
spark.driver.maxResultSize 1536m

spark.local.dir __SPARK_BKDATA_TEMP_DIR__

spark.default.parallelism 32
spark.rpc.message.maxSize 1024
spark.network.timeout 1200s
spark.sql.shuffle.partitions 100
spark.shuffle.sort.bypassMergeThreshold 300
#task
spark.task.maxFailures 8
spark.port.maxRetries 50

spark.dynamicAllocation.enabled true
spark.shuffle.service.enabled true
spark.shuffle.service.port 7337
spark.dynamicAllocation.minExecutors 1
spark.dynamicAllocation.maxExecutors 15
spark.dynamicAllocation.schedulerBacklogTimeout 1s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s
spark.dynamicAllocation.executorIdleTimeout 60s
spark.executor.heartbeatInterval 120s

spark.eventLog.enabled  true
spark.eventLog.dir  hdfs://__HDFS_CLUSTER_NAME__/app/spark/history/2.3

spark.sql.crossJoin.enabled true

spark.executor.memory 8g
spark.executor.cores 4
spark.executor.memoryOverhead 2g

spark.yarn.archive hdfs://__HDFS_CLUSTER_NAME2__/nfsserver/spark_support/2_4_7/spark-2.4.7-env.zip
spark.jars hdfs://__HDFS_CLUSTER_NAME2__/nfsserver/spark_support/batch_common/batch-common-0.1.0-jar-with-dependencies.jar
spark.yarn.stagingDir hdfs://__HDFS_CLUSTER_NAME2__/user/root/

spark.uc.batch.code.dataflow.url.prefix http://__BKDATA_DATAFLOWAPI_HOST__:__BKDATA_DATAFLOWAPI_PORT__/v3
spark.uc.batch.code.storekit.url.prefix http://__BKDATA_DATAHUBAPI_HOST__:__BKDATA_DATAHUBAPI_PORT__/v3
spark.uc.batch.code.datamanage.url.prefix http://__BKDATA_DATAMANAGEAPI_HOST__:__BKDATA_DATAMANAGEAPI_PORT__/v3
spark.uc.batch.code.databus.url.prefix http://__BKDATA_DATAHUBAPI_HOST__:__BKDATA_DATAHUBAPI_PORT__/v3

spark.bkdata.timezone __GEOG_AREA_TIMEZONE__

spark.uc.batch.code.timezone Asia/Shanghai
spark.uc.batch.code.monitor.enable True
spark.uc.batch.python.path __BKDATA_SPARK_CODE_PYENV_PATH__/bin/python

spark.bkdata.clean.tmp.dir.enable true
spark.bkdata.warehouse.dir __BK_HOME__/public/spark-warehouse
spark.bkdata.tmp.dir __SPARK_BKDATA_TEMP_DIR__


