#
# Tencent is pleased to support the open source community by making BK-BASE 蓝鲸基础计算平台 available.
#
# Copyright (C) 2019 THL A29 Limited, a Tencent company.  All rights reserved.
#
# BK-BASE 蓝鲸基础计算平台 is licensed under the MIT license.
#
# A copy of the MIT License is included in this file.
#
#
# Terms of the MIT License: # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
# and to permit persons to whom the Software is furnished to do so, subject to the following conditions: #
# The above copyright notice and this permission notice shall be included in all copies or substantial
# portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
# NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#

{
"job_id": "test_tokenizer",
"job_name": "test_tokenizer",
"job_type": "spark_mllib",
"run_mode": "dev",
"time_zone": "Asia/Shanghai",
"resource": {
"cluster_group": "default",
"queue_name": "root.dataflow.batch.default"
},
"nodes": {
"source": {
"591_sentence_rt": {
"id": "591_sentence_rt",
"input": {
"type": "hdfs",
"path": "hdfs://xxxx/591_sentence_rt",
"format": "parquet"
},
"name": "sentence_rt",
"fields": [
{
"origin": "",
"field": "id",
"type": "int",
"description": ""
},
{
"origin": "",
"field": "sentence",
"type": "string",
"description": ""
}
],
"description": "sentence rt",
"type": "data"
}
},
"transform": {
"591_test_tokenizer": {
"description": "591_test_tokenizer",
"fields": [
{
"origin": "",
"field": "sentence",
"type": "string",
"description": "sentence"
},
{
"origin": "",
"field": "words",
"type": "string",
"description": "words"
}
],
"interpreter": {
},
"processor": {
"name": "tokenizer",
"type": "untrained-run",
"args": {
"input_col": "sentence",
"output_col": "words"
}
},
"parents": [
"591_sentence_rt"
],
"id": "591_test_tokenizer",
"name": "test_tokenizer",
"type": "data"
},
"591_test_regex_tokenizer": {
"description": "test_regex_tokenizer",
"fields": [
{
"origin": "",
"field": "sentence",
"type": "string",
"description": "sentence"
},
{
"origin": "",
"field": "words",
"type": "string",
"description": "words"
}
],
"interpreter": {
},
"processor": {
"name": "regex_tokenizer",
"type": "untrained-run",
"args": {
"input_col": "sentence",
"output_col": "words",
"pattern": "\\W"
}
},
"parents": [
"591_sentence_rt"
],
"id": "591_test_regex_tokenizer",
"name": "test_regex_tokenizer",
"type": "data"
}
},
"sink": {
"591_test_tokenizer": {
"description": "591_test_tokenizer",
"fields": [
{
"origin": "",
"field": "sentence",
"type": "string",
"description": "sentence"
},
{
"origin": "",
"field": "words",
"type": "string",
"description": "words"
}
],
"output": {
"type": "hdfs",
"path": "hdfs://xxxx/591_test_tokenizer",
"format": "parquet",
"mode": "overwrite"
},
"id": "591_test_tokenizer",
"name": "test_tokenizer",
"type": "data"
},
"591_test_regex_tokenizer": {
"description": "test_regex_tokenizer",
"fields": [
{
"origin": "",
"field": "sentence",
"type": "string",
"description": "sentence"
},
{
"origin": "",
"field": "words",
"type": "string",
"description": "words"
}
],
"output": {
"type": "hdfs",
"path": "hdfs://xxxx/591_test_regex_tokenizer",
"format": "parquet",
"mode": "overwrite"
},
"id": "591_test_regex_tokenizer",
"name": "test_regex_tokenizer",
"type": "data"
}
}
}
}
